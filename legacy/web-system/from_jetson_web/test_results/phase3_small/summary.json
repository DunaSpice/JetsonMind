{
  "phase": "phase3_small",
  "total_time_minutes": 2.9,
  "models_tested": 3,
  "successful": 2,
  "failed": 1,
  "completion_time": "2025-09-20T23:48:53.233698",
  "results": [
    {
      "model": "Qwen/Qwen2.5-0.5B-Instruct",
      "phase": "phase3_small",
      "status": "success",
      "load_time": 14.32,
      "inference_time": 2.55,
      "tokens_per_second": 13.04,
      "output": "Hello, how are you? I'm currently working on a project that involves creating an interactive web application using React and Next.js.",
      "error": "",
      "gpu_memory_gb": 0.93,
      "peak_gpu_temp": 0,
      "peak_memory_percent": 52.3,
      "safety_alerts": [],
      "pre_test_stats": {
        "timestamp": "2025-09-20T23:46:03.641048",
        "cpu_percent": 0.2,
        "cpu_temp_c": 53.406,
        "memory_percent": 30.8,
        "memory_used_gb": 2.0280990600585938,
        "memory_available_gb": 5.147911071777344,
        "disk_used_percent": 6.3,
        "disk_free_gb": 3374.149215698242,
        "load_average": 0.4794921875,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      },
      "post_test_stats": {
        "timestamp": "2025-09-20T23:46:23.601056",
        "cpu_percent": 0.7,
        "cpu_temp_c": 53.5,
        "memory_percent": 54.9,
        "memory_used_gb": 3.822582244873047,
        "memory_available_gb": 3.358051300048828,
        "disk_used_percent": 6.3,
        "disk_free_gb": 3373.2180366516113,
        "load_average": 0.4228515625,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      }
    },
    {
      "model": "Qwen/Qwen2.5-1.5B-Instruct",
      "phase": "phase3_small",
      "status": "success",
      "load_time": 41.98,
      "inference_time": 2.4,
      "tokens_per_second": 10.31,
      "output": "Hello, how are you? I'm sorry, as an AI language model, I don't have feelings or emotions. However,",
      "error": "",
      "gpu_memory_gb": 2.88,
      "peak_gpu_temp": 0,
      "peak_memory_percent": 96.6,
      "safety_alerts": [
        "\ud83d\udd25 Memory critical: 96.6%"
      ],
      "pre_test_stats": {
        "timestamp": "2025-09-20T23:47:07.869070",
        "cpu_percent": 0.2,
        "cpu_temp_c": 53.125,
        "memory_percent": 54.5,
        "memory_used_gb": 3.7913246154785156,
        "memory_available_gb": 3.3893203735351562,
        "disk_used_percent": 6.3,
        "disk_free_gb": 3373.2180252075195,
        "load_average": 0.1982421875,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      },
      "post_test_stats": {
        "timestamp": "2025-09-20T23:47:55.362704",
        "cpu_percent": 4.5,
        "cpu_temp_c": 54.25,
        "memory_percent": 98.5,
        "memory_used_gb": 7.097412109375,
        "memory_available_gb": 0.11119461059570312,
        "disk_used_percent": 6.4,
        "disk_free_gb": 3370.3318405151367,
        "load_average": 1.0458984375,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      }
    },
    {
      "model": "meta-llama/Llama-3.2-1B-Instruct",
      "phase": "phase3_small",
      "status": "failed",
      "load_time": 0,
      "inference_time": 0,
      "tokens_per_second": 0,
      "output": "",
      "error": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct.\n401 Client Error. (Request ID: Root=1-68cf3d5a-722b69e25d4fc5d9221abc6b;f5ebf5d6-25df-4f08-bdc8-16036b781deb)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct/resolve/main/config.json.\nAccess to model meta-llama/Llama-3.2-1B-Instruct is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "gpu_memory_gb": 0,
      "peak_gpu_temp": 0,
      "peak_memory_percent": 0,
      "safety_alerts": [
        "\ud83d\udd25 Memory critical: 96.6%",
        "\ud83d\udd25 Memory critical: 98.5%"
      ],
      "pre_test_stats": {
        "timestamp": "2025-09-20T23:48:39.941251",
        "cpu_percent": 0.2,
        "cpu_temp_c": 53.625,
        "memory_percent": 68.5,
        "memory_used_gb": 4.857460021972656,
        "memory_available_gb": 2.3457984924316406,
        "disk_used_percent": 6.4,
        "disk_free_gb": 3370.331829071045,
        "load_average": 0.57373046875,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      },
      "post_test_stats": {
        "timestamp": "2025-09-20T23:48:42.192545",
        "cpu_percent": 0.2,
        "cpu_temp_c": 53.781,
        "memory_percent": 68.5,
        "memory_used_gb": 4.860431671142578,
        "memory_available_gb": 2.3428115844726562,
        "disk_used_percent": 6.4,
        "disk_free_gb": 3370.3318252563477,
        "load_average": 0.52734375,
        "gpu_temp_c": 0,
        "gpu_memory_used_mb": 0,
        "gpu_memory_total_mb": 0,
        "gpu_utilization_percent": 0
      }
    }
  ]
}